{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\OneDrive\\Documents\\Projects\\VidSum-AI\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.80k/1.80k [00:00<00:00, 3.53MB/s]\n",
      "c:\\Users\\ASUS\\OneDrive\\Documents\\Projects\\VidSum-AI\\env\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ASUS\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading pytorch_model.bin: 100%|██████████| 1.22G/1.22G [02:06<00:00, 9.65MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 26.0/26.0 [00:00<00:00, 13.0kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 3.23MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 642kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('best_model\\\\sshleifer/distilbart-cnn-12-6\\\\tokenizer_config.json',\n",
       " 'best_model\\\\sshleifer/distilbart-cnn-12-6\\\\special_tokens_map.json',\n",
       " 'best_model\\\\sshleifer/distilbart-cnn-12-6\\\\vocab.json',\n",
       " 'best_model\\\\sshleifer/distilbart-cnn-12-6\\\\merges.txt',\n",
       " 'best_model\\\\sshleifer/distilbart-cnn-12-6\\\\added_tokens.json',\n",
       " 'best_model\\\\sshleifer/distilbart-cnn-12-6\\\\tokenizer.json')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import os\n",
    "\n",
    "# Define the model and tokenizer names\n",
    "model_name = \"sshleifer/distilbart-cnn-12-6\"\n",
    "\n",
    "\n",
    "# Download the model and tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory path for saving the model\n",
    "best_model_dir = \"../best_model\"\n",
    "os.makedirs(best_model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../best_model\\\\sshleifer/distilbart-cnn-12-6\\\\tokenizer_config.json',\n",
       " '../best_model\\\\sshleifer/distilbart-cnn-12-6\\\\special_tokens_map.json',\n",
       " '../best_model\\\\sshleifer/distilbart-cnn-12-6\\\\vocab.json',\n",
       " '../best_model\\\\sshleifer/distilbart-cnn-12-6\\\\merges.txt',\n",
       " '../best_model\\\\sshleifer/distilbart-cnn-12-6\\\\added_tokens.json',\n",
       " '../best_model\\\\sshleifer/distilbart-cnn-12-6\\\\tokenizer.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and tokenizer to the specified directory\n",
    "model.save_pretrained(os.path.join(best_model_dir, model_name))\n",
    "tokenizer.save_pretrained(os.path.join(best_model_dir, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the locally saved model and tokenizer\n",
    "model_dir = \"../best_model/sshleifer/distilbart-cnn-12-6\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,   134,     4, 15347,   196,    10,  3748,  2502,    13,   569,\n",
      "         39186,  1938,   634, 48042,     8,    61,    74, 12348,     8, 40402,\n",
      "             5,  3424,     4, 50118,   176,     4, 30374,  2117,   250,   118,\n",
      "         27199,  1741,    13, 37118,     8, 13540, 35093,    12,   565, 37236,\n",
      "         30634, 12606,    13,  5338, 13540, 18581,  3916,  1938, 12606,  1437,\n",
      "         50118,   246,     4, 40378, 14133,     5,   819,     9, 17194,   634,\n",
      "         14823,  1437, 13540, 30876,   791,     8,   248,  5061,  8800, 12606,\n",
      "          1471,     7,  2205,  1322,     5,   819,    19,   194,     9,     5,\n",
      "          1808,  5338, 39186,  1938,  3777, 50118,   306,     4, 10630,    24,\n",
      "          3013,    13,  1434,     7,  1346,     5,  1383,     9,     5,   569,\n",
      "            19,  9865,  1351, 50118,   245,     4,   926,  5536,  9700,    10,\n",
      "         13540, 45646,   716, 12606,  2115,     5,   569,  4819,     7,   223,\n",
      "           620,   282,   625,     5,  7630,   281,  5846,    84,  1498,  4819,\n",
      "             2]])\n"
     ]
    }
   ],
   "source": [
    "input_text = \"\"\"1. Developed a web application for video summarization using Flask and which would transcript and summarize the videos.\n",
    "2. Used OpenAi Whisper for transcription and **fine-Tuned BART** for Video **summarization** \n",
    "3. Evaluated the performance of algorithm using metric  **BLEU and ROUGE** score to campare the performance with state of the art Video summarization Technology\n",
    "4. Made it easier for users to understand the content of the video with minimal effort\n",
    "5. Develped a **Audio based** upon the video summary to understnad the evasily our complete summary\"\"\"\n",
    "\n",
    "# Tokenize the input text\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "print(input_ids)\n",
    "\n",
    "\n",
    "# Use output_text in your application as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561\n"
     ]
    }
   ],
   "source": [
    "print(len(input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Developed a web application for video summarization using Flask. Used OpenAi Whisper for transcription and BART for video summary. Evaluated the performance of algorithm using metric  **BLEU and ROUGE score to campare the performance with state of the art Video summarization Technology.\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "with torch.no_grad():\n",
    "    output = model.generate(input_ids, max_length=150, num_beams=4, length_penalty=2.0, early_stopping=True)\n",
    "\n",
    "# Decode the generated output\n",
    "output_text = tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Developed a web application for video summarization using Flask. Used OpenAi Whisper for transcription and BART for video summary. Evaluated the performance of algorithm using metric  **BLEU and ROUGE score to campare the performance with state of the art Video summarization Technology.\n",
      "288\n"
     ]
    }
   ],
   "source": [
    "print(output_text)\n",
    "print(len(output_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
